{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets optuna peft torch psutil wandb matplotlib rouge-score -q\n",
        "!pip install evaluate\n",
        "!pip install rouge-score bert-score -q"
      ],
      "metadata": {
        "id": "a-PJLUYLoFRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "\n",
        "csv_path = \"arabic_summaries_5000_v2.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.1, random_state=42)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "fRlKkvhbmSEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments: Normal fine tune"
      ],
      "metadata": {
        "id": "o74UUToEBP8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import importlib\n",
        "import normal_finetuning,  qlora_finetuning, utils, prefix_finetuning, evaluation\n",
        "from normal_finetuning import finetune_model as normal_finetune\n",
        "from qlora_finetuning import finetune_model as qlora_finetune\n",
        "from prefix_finetuning import finetune_model as prefix_finetune\n",
        "from evaluation import run_evluation\n",
        "\n",
        "importlib.reload(prefix_finetuning)\n",
        "importlib.reload(normal_finetuning)\n",
        "importlib.reload(utils)\n",
        "importlib.reload(qlora_finetuning)"
      ],
      "metadata": {
        "id": "Gv8ObqLvmFA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_prompt = None  # Or \"لخص النص التالي:\"\n",
        "template = \"{text} {summary}\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "trainer, stats = normal_finetune(model_name, train_dataset, val_dataset,\n",
        "                                 learning_rate=2e-5, batch_size=2, num_epochs=2,\n",
        "                                 use_wandb=True, prompt=arabic_prompt,\n",
        "                                 template = template,\n",
        "                                 grad_acc_step=16, OUTPUT_DIR=OUTPUT_DIR)\n",
        "\n",
        "print(f\"Normal Fine-Tuning Stats: {stats}\")"
      ],
      "metadata": {
        "id": "XHj4KIzWW8oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments: Lora/QLora"
      ],
      "metadata": {
        "id": "HuXU7oU1cUd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kDYIZBNsgOf9",
        "outputId": "8a336b41-845e-4757-a3d3-8e49bd6f52e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.39.0)\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Using cached bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "Installing collected packages: bitsandbytes\n",
            "  Attempting uninstall: bitsandbytes\n",
            "    Found existing installation: bitsandbytes 0.39.0\n",
            "    Uninstalling bitsandbytes-0.39.0:\n",
            "      Successfully uninstalled bitsandbytes-0.39.0\n",
            "Successfully installed bitsandbytes-0.45.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_prompt = None  # Or \"لخص النص التالي:\"\n",
        "template = \"النص:{text}الملخص:{summary}\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/NLPProject\"\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "#first parameter can be lora or qlora\n",
        "trainer, stats = qlora_finetune(\"lora\",model_name, train_dataset, val_dataset,\n",
        "                                 learning_rate=2e-5, batch_size=2, num_epochs=3,\n",
        "                                 use_wandb=True, prompt=arabic_prompt,\n",
        "                                 template = template, one_shot_text = None,\n",
        "                                 one_shot_summary=None,\n",
        "                                 lora_r = 64,\n",
        "                                 grad_acc_step=16, OUTPUT_DIR=OUTPUT_DIR)\n",
        "\n",
        "print(f\"Normal Fine-Tuning Stats: {stats}\")"
      ],
      "metadata": {
        "id": "MAuf1oBw0trR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments: Prefix tuning"
      ],
      "metadata": {
        "id": "xCzoYmBWnVHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wlarabic_prompt = \"لخص:\"  # Or \"لخص النص التالي:\"\n",
        "template = \"النص:{text}الملخص:{summary}\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "\n",
        "trainer, stats = prefix_finetune(model_name, train_dataset, val_dataset,\n",
        "                                 learning_rate=2e-4, batch_size=2, num_epochs=3,\n",
        "                                 use_wandb=True, prompt=arabic_prompt,\n",
        "                                 template = template, one_shot_text = None,\n",
        "                                 one_shot_summary=None,\n",
        "                                 num_virtual_tokens = 16,\n",
        "                                 grad_acc_step=16, prefix_projection=True,OUTPUT_DIR=OUTPUT_DIR)\n",
        "\n",
        "print(f\"Normal Fine-Tuning Stats: {stats}\")"
      ],
      "metadata": {
        "id": "vfP0joDonXzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiemtns: One shot with prefix tuning"
      ],
      "metadata": {
        "id": "_eniu0Cz7UmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "shot_index = 1\n",
        "one_shot_text = df['text'][shot_index]\n",
        "one_shot_summary = df['summary'][shot_index]\n",
        "df = df.drop(index=shot_index)\n",
        "\n",
        "train_val_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "train_df, val_df = train_test_split(train_val_df, test_size=0.1, random_state=42)\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "IaPpwHC47X9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78a5ebf-ddde-4b9b-f687-8f1d830a1a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 3599, Val size: 400, Test size: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wlarabic_prompt = \"لخص:\"  # Or \"لخص النص التالي:\"\n",
        "template = \"النص:{text}الملخص:{summary}\"\n",
        "OUTPUT_DIR = \"./\"\n",
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "\n",
        "trainer, stats = prefix_finetune(model_name, train_dataset, val_dataset,\n",
        "                                 learning_rate=2e-4, batch_size=2, num_epochs=3,\n",
        "                                 use_wandb=True, prompt=arabic_prompt,\n",
        "                                 template = template, one_shot_text = one_shot_text,\n",
        "                                 one_shot_summary=one_shot_summary,\n",
        "                                 num_virtual_tokens = 16,\n",
        "                                 grad_acc_step=16, prefix_projection=True,OUTPUT_DIR=OUTPUT_DIR)\n",
        "\n",
        "print(f\"Normal Fine-Tuning Stats: {stats}\")"
      ],
      "metadata": {
        "id": "dtQLrx9iQHFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OuExKPa-nj1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "Re8cxXuXnkiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "checkpoint_path = \"../\"\n",
        "template = \"النص:{text}الملخص:{summary}\"\n",
        "output_split = \"الملخص:\"\n",
        "batch_size=10\n",
        "run_evluation(test_dataset,model_name, checkpoint_path, template, output_split,batch_size, prompt=None):"
      ],
      "metadata": {
        "id": "VL_LYZRlnm9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}